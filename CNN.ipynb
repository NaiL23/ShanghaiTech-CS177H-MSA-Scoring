{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "separate-atmosphere",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff351dca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99578c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\craig\\anaconda3\\envs\\PyTorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_PATH = Path() \n",
    "sys.path.append(str(PROJECT_PATH))\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "DATASET_PATH = Path() / \"dataset\" / \"CASP14_fm\"\n",
    "MODEL_PATH       = PROJECT_PATH / \"model\"\n",
    "EMBDEDDINGS_PATH = PROJECT_PATH / \"embeddings\"\n",
    "\n",
    "# hyperparameters\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "checkpoint_epoch = 0\n",
    "model_name = \"cnn_256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1658a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "from dataset import EmbeddingScoreDataset, PairDataset\n",
    "\n",
    "train_dataset = EmbeddingScoreDataset(EMBDEDDINGS_PATH, DATASET_PATH, is_train = True)\n",
    "test_dataset  = PairDataset(EMBDEDDINGS_PATH, DATASET_PATH, is_train = False)\n",
    "\n",
    "NUM_GPU = torch.cuda.device_count()\n",
    "\n",
    "train_loader = Data.DataLoader(train_dataset, batch_size = BATCH_SIZE, num_workers = 0, pin_memory = True, shuffle = True)\n",
    "test_loader  = Data.DataLoader(test_dataset, batch_size = 1, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601fb035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=6,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=6,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=0\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(432432, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, self.num_flat_features(x)) \n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x)) \n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bbbc140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=432432, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=32, bias=True)\n",
      "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN().cuda()\n",
    "\n",
    "NUM_GPU = torch.cuda.device_count()\n",
    "USE_PARALLEL = NUM_GPU > 1\n",
    "if USE_PARALLEL :\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4ff2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training cnn_256 model from the 1st epoch.\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "if checkpoint_epoch > 0 :\n",
    "    checkpoint = torch.load(MODEL_PATH / f\"model_{model_name}_epoch{checkpoint_epoch}.pth\")\n",
    "    (model.module if USE_PARALLEL else model).load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f\"The {model_name} model loaded has been trained for {epoch} epoche(s), with {checkpoint['train_mse']} training loss, {checkpoint['valid_mse']} validation MSE and {checkpoint['test_acc']} test accuracy. \")\n",
    "else :\n",
    "    print(f\"Start training {model_name} model from the 1st epoch.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de13e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_test_metric(model, print_wrong_predictions = False, print_correct_predictions = False):\n",
    "    model.eval()\n",
    "    mse, correct, tot = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total = len(test_loader), ncols = 80, file = sys.stdout) as bar:\n",
    "            for sample in test_loader :\n",
    "                x1, x2, y1, y2 = sample[\"embedding1\"].cuda(), sample[\"embedding2\"].cuda(), sample[\"score1\"].cuda(), sample[\"score2\"].cuda()\n",
    "                x, y = torch.vstack([x1, x2]), torch.vstack([y1, y2])\n",
    "                \n",
    "                predictor = model.module if USE_PARALLEL else model\n",
    "                pred = torch.sigmoid(predictor.regressor(x)) if model_name[:4] == 'pair' else predictor(x)\n",
    "\n",
    "                if torch.argmax(y) == torch.argmax(pred) :\n",
    "                    correct += 1\n",
    "                    if print_correct_predictions:\n",
    "                        for name, y_gt, y_pred in zip([sample['name1'][0], sample['name2'][0]], y, pred) :\n",
    "                            tqdm.write(f\"{name:>20}  y_gt:{y_gt.item():.4f}  y_pred:{y_pred.item() :.4f}\")\n",
    "                        tqdm.write(\"-----------------------------------------------\")\n",
    "                else :\n",
    "                    if print_wrong_predictions:\n",
    "                        for name, y_gt, y_pred in zip([sample['name1'][0], sample['name2'][0]], y, pred) :\n",
    "                            tqdm.write(f\"{name:>20}  y_gt:{y_gt.item() :.4f}  y_pred:{y_pred.item() :.4f}\")\n",
    "                        tqdm.write(\"===================================================\")\n",
    "                \n",
    "                mse += torch.sum((y - pred) ** 2).item()\n",
    "                tot += 2\n",
    "\n",
    "                bar.set_postfix({\n",
    "                    \"acc\": f\"{correct / (tot // 2):.4f}\",\n",
    "                    \"mse\": f\"{mse / tot:.4f}\"\n",
    "                })\n",
    "                bar.update(1)\n",
    "    \n",
    "    return {'accuracy' : correct / (tot // 2), 'mse' : mse / tot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0379dedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 1/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:24<00:00,  3.47it/s, loss=0.04622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 79.81it/s, acc=0.9684, mse=0.0333]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 2/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:20<00:00,  4.03it/s, loss=0.01755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 81.67it/s, acc=0.9474, mse=0.0191]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 3/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.94it/s, loss=0.01250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.38it/s, acc=0.9579, mse=0.0160]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 4/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.92it/s, loss=0.00886]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 80.15it/s, acc=0.9684, mse=0.0178]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 5/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:20<00:00,  4.03it/s, loss=0.00848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.52it/s, acc=0.9684, mse=0.0148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 6/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:20<00:00,  4.03it/s, loss=0.00603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 84.65it/s, acc=0.9684, mse=0.0137]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 7/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.88it/s, loss=0.00571]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 85.10it/s, acc=0.9579, mse=0.0152]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 8/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.87it/s, loss=0.00530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 81.46it/s, acc=0.9474, mse=0.0153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch# 9/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.89it/s, loss=0.00425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 81.11it/s, acc=0.9579, mse=0.0134]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#10/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.93it/s, loss=0.00319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 75.86it/s, acc=0.9684, mse=0.0137]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#11/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.83it/s, loss=0.00309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 75.74it/s, acc=0.9789, mse=0.0144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#12/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.89it/s, loss=0.00261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 83.26it/s, acc=0.9684, mse=0.0131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#13/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.90it/s, loss=0.00231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 80.02it/s, acc=0.9684, mse=0.0133]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#14/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.91it/s, loss=0.00243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.45it/s, acc=0.9684, mse=0.0139]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#15/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.96it/s, loss=0.00173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.45it/s, acc=0.9789, mse=0.0129]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#16/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.98it/s, loss=0.00179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.59it/s, acc=0.9789, mse=0.0130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#17/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.95it/s, loss=0.00173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 81.25it/s, acc=0.9789, mse=0.0124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#18/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.97it/s, loss=0.00128]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.16it/s, acc=0.9789, mse=0.0126]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#19/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.98it/s, loss=0.00106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.88it/s, acc=0.9789, mse=0.0130]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[epoch#20/20][ 2656/ 2660]: 100%|███████████████████████████████████████████████████| 84/84 [00:21<00:00,  3.99it/s, loss=0.00097]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 95/95 [00:01<00:00, 82.73it/s, acc=0.9789, mse=0.0126]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(checkpoint_epoch + 1, EPOCHS + 1):\n",
    "    losses, losses_reg, tot = 0, 0, 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total = len(train_loader), ncols = 130) as bar:\n",
    "        for batch, sample in enumerate(train_loader) :\n",
    "            \n",
    "            bar.set_description(f\"[epoch#{epoch:>2}/{EPOCHS:>2}][{batch * BATCH_SIZE:>5}/{len(train_dataset):>5}]\")\n",
    "\n",
    "            x, y = sample[\"embedding\"].cuda(), sample[\"score\"].cuda()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred,y)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()     \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses += loss.item() * len(sample)\n",
    "            tot += len(sample)\n",
    "\n",
    "            bar.set_postfix({\n",
    "                # \"batch loss\" : f\"{loss.item():.5f}\",\n",
    "                \"loss\": f\"{losses / tot:.5f}\"\n",
    "            })\n",
    "            bar.update(1)\n",
    "\n",
    "    test_metric =  calc_test_metric(model)\n",
    "    train_loss, train_mse, test_acc, valid_mse = losses / tot, losses_reg / tot, test_metric['accuracy'], test_metric['mse']\n",
    "    torch.save({\n",
    "        'epoch'               : epoch,\n",
    "        'model_state_dict'    : (model.module if USE_PARALLEL else model).state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_mse'           : train_mse,\n",
    "        'train_loss'          : train_loss,\n",
    "        'valid_mse'           : valid_mse,\n",
    "        'test_acc'            : test_acc\n",
    "    }, MODEL_PATH / f\"model_{model_name}_epoch{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1592ddde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1030-D1_original_fm  y_gt:0.8572  y_pred:0.7634                                \n",
      "  T1030-D1_rand13_fm  y_gt:0.8149  y_pred:0.8119                                \n",
      "===================================================                             \n",
      "T1047s2-D2_rand16_fm  y_gt:0.7530  y_pred:0.8398                                \n",
      " T1047s2-D2_rand5_fm  y_gt:0.9398  y_pred:0.7485                                \n",
      "===================================================                             \n",
      "100%|███████████████████| 95/95 [00:01<00:00, 64.70it/s, acc=0.9789, mse=0.0126]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9789473684210527, 'mse': 0.012627777705998405}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_test_metric(model, print_wrong_predictions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afa524c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e5204d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
